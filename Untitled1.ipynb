{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7e15f2-9634-4ec0-bcdb-949ed06afd74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Data exploration \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m data\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# exploring data\u001b[39;00m\n\u001b[1;32m     20\u001b[0m data\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import math\n",
    "\n",
    "\n",
    "# Data exploration \n",
    "data.sort_values('Year', ascending=True)\n",
    "\n",
    "\n",
    "# exploring data\n",
    "data.describe()\n",
    "\n",
    "print(data.info())\n",
    "print('\\n')\n",
    "print('Need to convert objects into categorical variables')\n",
    "\n",
    "print(data.isna().any())\n",
    "print('no missing data')\n",
    "\n",
    "\n",
    "pd.Series(data['Year'].unique()).sort_values(ascending = True)\n",
    "\n",
    "# Grouping Sales Volume per model, per year. Will ignore geography for now\n",
    "modelsales_volume = data.groupby(['Model','Year'], as_index=False)['Sales_Volume'].sum().sort_values(by=['Model','Year'])\n",
    "print(modelsales_volume.head())\n",
    "print(modelsales_volume.shape)\n",
    "\n",
    "\n",
    "# Number of unique models\n",
    "models = modelsales_volume['Model'].unique()\n",
    "n_models = len(models)\n",
    "\n",
    "# Define grid size (e.g., 3 rows × 4 cols for 11 models)\n",
    "n_cols = 4\n",
    "n_rows = math.ceil(n_models / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 10), sharex=True, sharey=True)\n",
    "axes = axes.flatten()  # Flatten axes array for easy indexing\n",
    "\n",
    "for i, model_name in enumerate(models):\n",
    "    ax = axes[i]\n",
    "    group = modelsales_volume[modelsales_volume['Model'] == model_name].sort_values('Year')\n",
    "    ax.plot(group['Year'], group['Sales_Volume'] / 1_000_000, marker='o', color='tab:blue')\n",
    "    ax.set_title(model_name)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Label only outer plots\n",
    "for ax in axes:\n",
    "    ax.label_outer()\n",
    "\n",
    "# Common labels\n",
    "fig.text(0.5, 0.04, 'Year', ha='center', fontsize=12)\n",
    "fig.text(0.04, 0.5, 'Sales Volume (Millions)', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "fig.suptitle('Sales Volume Trend by Model', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "# Initalize figure \n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "for model_name, group in modelsales_volume.groupby('Model'):\n",
    "    ax.plot(group['Year'], group['Sales_Volume'], marker='o', label=model_name)\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Sales Volume')\n",
    "ax.set_title('Sales Volume Trend by Model')\n",
    "ax.legend(title='Model')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Number of unique models\n",
    "models = regionsales_volume['Region'].unique()\n",
    "n_models = len(models)\n",
    "\n",
    "# Define grid size (e.g., 3 rows × 4 cols for 11 models)\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(n_models / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 10), sharex=True, sharey=True)\n",
    "axes = axes.flatten()  # Flatten axes array for easy indexing\n",
    "\n",
    "for i, model_name in enumerate(models):\n",
    "    ax = axes[i]\n",
    "    group = regionsales_volume[regionsales_volume['Region'] == model_name].sort_values('Year')\n",
    "    ax.plot(group['Year'], group['Sales_Volume'] / 1_000_000, marker='o', color='tab:blue')\n",
    "    ax.set_title(model_name)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Label only outer plots\n",
    "for ax in axes:\n",
    "    ax.label_outer()\n",
    "\n",
    "# Common labels\n",
    "fig.text(0.5, 0.04, 'Year', ha='center', fontsize=12)\n",
    "fig.text(0.04, 0.5, 'Sales Volume (Millions)', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "fig.suptitle('Sales Volume Trend by Region', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "# Initalize figure \n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "for model_name, group in regionsales_volume.groupby('Region'):\n",
    "    ax.plot(group['Year'], group['Sales_Volume'], marker='o', label=model_name)\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Sales Volume')\n",
    "ax.set_title('Sales Volume Trend by Region')\n",
    "ax.legend(title='Region')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#  Although Cyclical, I see a growth pattern in North America, with peaks, pushing to new volumes. This is expected to the sensitivity of car sales when compared to economic conditions, interest rates, and etc.\n",
    "\n",
    "\n",
    "# Creating classification model that will predict whether a model will be classified as high or low in Sales, based on Features\n",
    "\n",
    "\n",
    "# Step 1: Convert Datatypes that are objects into ML Friendly format \n",
    "\n",
    "print(list(data.select_dtypes(include='object').columns))\n",
    "print('\\n')\n",
    "print(data.select_dtypes(include='object').head())\n",
    "\n",
    "# Copying dataset to maintain source data\n",
    "data2 = data.copy()\n",
    "print('\\n')\n",
    "\n",
    "# Create and fit the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "data2['Region_coded'] = label_encoder.fit_transform(data2['Region'])\n",
    "\n",
    "# Create a readable dictionary mapping\n",
    "region_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# Display the mapping\n",
    "print(\"Region Encoding Dictionary:\")\n",
    "for region, code in region_mapping.items():\n",
    "    print(f\"{region}: {code}\")\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "data2.head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a fresh LabelEncoder for each categorical column\n",
    "label_encoder_model = LabelEncoder()\n",
    "label_encoder_color = LabelEncoder()\n",
    "label_encoder_fuel = LabelEncoder()\n",
    "label_encoder_trans = LabelEncoder()\n",
    "label_encoder_sales = LabelEncoder()  # new encoder for sales classification\n",
    "\n",
    "# Encode categorical columns and create mapping dictionaries\n",
    "data2['Model_coded'] = label_encoder_model.fit_transform(data2['Model'])\n",
    "model_mapping = dict(zip(label_encoder_model.classes_, label_encoder_model.transform(label_encoder_model.classes_)))\n",
    "\n",
    "data2['Color_coded'] = label_encoder_color.fit_transform(data2['Color'])\n",
    "color_mapping = dict(zip(label_encoder_color.classes_, label_encoder_color.transform(label_encoder_color.classes_)))\n",
    "\n",
    "data2['Fuel_Type_coded'] = label_encoder_fuel.fit_transform(data2['Fuel_Type'])\n",
    "fuel_type_mapping = dict(zip(label_encoder_fuel.classes_, label_encoder_fuel.transform(label_encoder_fuel.classes_)))\n",
    "\n",
    "data2['Transmission_coded'] = label_encoder_trans.fit_transform(data2['Transmission'])\n",
    "transmission_mapping = dict(zip(label_encoder_trans.classes_, label_encoder_trans.transform(label_encoder_trans.classes_)))\n",
    "\n",
    "# Encode Sales_Classification (High/Low → 1/0)\n",
    "data2['Sales_Classification_coded'] = label_encoder_sales.fit_transform(data2['Sales_Classification'])\n",
    "sales_mapping = dict(zip(label_encoder_sales.classes_, label_encoder_sales.transform(label_encoder_sales.classes_)))\n",
    "\n",
    "# Print mappings clearly\n",
    "print(\"Model Encoding Dictionary:\")\n",
    "for model, code in model_mapping.items():\n",
    "    print(f\"{model}: {code}\")\n",
    "\n",
    "print(\"\\nColor Encoding Dictionary:\")\n",
    "for color, code in color_mapping.items():\n",
    "    print(f\"{color}: {code}\")\n",
    "\n",
    "print(\"\\nFuel Type Encoding Dictionary:\")\n",
    "for fuel, code in fuel_type_mapping.items():\n",
    "    print(f\"{fuel}: {code}\")\n",
    "\n",
    "print(\"\\nTransmission Encoding Dictionary:\")\n",
    "for trans, code in transmission_mapping.items():\n",
    "    print(f\"{trans}: {code}\")\n",
    "\n",
    "print(\"\\nSales Classification Encoding Dictionary:\")\n",
    "for sale_class, code in sales_mapping.items():\n",
    "    print(f\"{sale_class}: {code}\")\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "data2.head()\n",
    "\n",
    "# Converting year to age of car\n",
    "data2['Age'] = 2025 - data2['Year']\n",
    "data2.head()\n",
    "\n",
    "\n",
    "data_clean = data2.copy()\n",
    "data_clean.drop(['Model','Year','Region','Color','Fuel_Type','Transmission', 'Sales_Classification'],axis=1, inplace=True)\n",
    "data_clean.head()\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Splitting data into X and Y datasets\n",
    "X= data_clean.drop(columns='Sales_Classification_coded')\n",
    "y = data_clean['Sales_Classification_coded']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Regularization types\n",
    "    'solver': ['liblinear', 'saga'],  # Solvers\n",
    "    'max_iter': [100, 200, 300]  # Number of iterations\n",
    "}\n",
    "\n",
    "log_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(log_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_log_model = grid_search.best_estimator_\n",
    "\n",
    "# Make Predictions \n",
    "y_pred = best_log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# Convert to a pandas DataFrame with labeled rows and columns\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['True', 'False'], columns=['Predicted True', 'Predicted False'])\n",
    "\n",
    "print(conf_matrix_df)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0d88a-d555-4a59-ba8a-bbe16d881e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534be029-ba82-4e0c-ac76-c1dac28b7107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
